{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e86c3709",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-28T03:34:01.405941Z",
     "start_time": "2023-03-28T03:33:58.429176Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Introductory Examples for the NLTK Book ***\n",
      "Loading text1, ..., text9 and sent1, ..., sent9\n",
      "Type the name of the text or sentence to view it.\n",
      "Type: 'texts()' or 'sents()' to list the materials.\n",
      "text1: Moby Dick by Herman Melville 1851\n",
      "text2: Sense and Sensibility by Jane Austen 1811\n",
      "text3: The Book of Genesis\n",
      "text4: Inaugural Address Corpus\n",
      "text5: Chat Corpus\n",
      "text6: Monty Python and the Holy Grail\n",
      "text7: Wall Street Journal\n",
      "text8: Personals Corpus\n",
      "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "#stopwords = set(STOPWORDS)\n",
    "import itertools\n",
    "import nltk\n",
    "# nltk.download()\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download(\"punkt\")\n",
    "# nltk.download('corpora')\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import ne_chunk\n",
    "from nltk.util import ngrams\n",
    "from nltk.book import *\n",
    "\n",
    "\n",
    "\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "\n",
    "import re\n",
    "import string\n",
    "\n",
    "\n",
    "\n",
    "#read the files\n",
    "train = pd.read_csv(\"/Users/legfot/Documents/content/data/train.csv\", encoding = 'ISO-8859-1')\n",
    "test = pd.read_csv(\"/Users/legfot/Documents/content/data/test.csv\", encoding = 'ISO-8859-1')\n",
    "test_y = pd.read_csv(\"/Users/legfot/Documents/content/data/test_labels.csv\", encoding = 'ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6c427dc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-28T03:34:25.402411Z",
     "start_time": "2023-03-28T03:34:06.838030Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "#removes \\n\n",
    "train['preprocess'] = train.apply(lambda row: row['comment_text'].replace(\"\\n\",\" \"), axis=1) \n",
    "test['preprocess'] = test.apply(lambda row: row['comment_text'].replace(\"\\n\",\" \"), axis=1)\n",
    "\n",
    "#removes urls\n",
    "train['preprocess']=train.apply(lambda row: re.sub('http://\\S+|https://\\S+', 'urls',row['preprocess']).lower(), axis=1)\n",
    "test['preprocess']=test.apply(lambda row: re.sub('http://\\S+|https://\\S+', 'urls',row['preprocess']).lower(), axis=1)\n",
    "\n",
    "#remove all non-alphanumeric values(Except single quotes)\n",
    "train['preprocess']=train.apply(lambda row: re.sub('[^A-Za-z\\' ]+', '',row['preprocess']).lower(), axis=1)\n",
    "test['preprocess']=test.apply(lambda row: re.sub('[^A-Za-z\\' ]+', '',row['preprocess']).lower(), axis=1)\n",
    "\n",
    "#remove stopwords as they occupy major chunk of the vocabulary\n",
    "train['preprocess'] = train['preprocess'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
    "test['preprocess'] = test['preprocess'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
    "\n",
    "#removes all additional spaces\n",
    "train['preprocess']=train.apply(lambda row: re.sub('  +', ' ',row['preprocess']).strip(), axis=1)\n",
    "test['preprocess']=test.apply(lambda row: re.sub('  +', ' ',row['preprocess']).strip(), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "221eacdf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-28T03:44:04.854505Z",
     "start_time": "2023-03-28T03:44:04.833943Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>preprocess</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>explanation edits made username hardcore metal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>d'aww matches background colour i'm seemingly ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>hey man i'm really trying edit war guy constan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>can't make real suggestions improvement wonder...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>sir hero chance remember page that's</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \\\n",
       "0             0        0       0       0              0   \n",
       "1             0        0       0       0              0   \n",
       "2             0        0       0       0              0   \n",
       "3             0        0       0       0              0   \n",
       "4             0        0       0       0              0   \n",
       "\n",
       "                                          preprocess  \n",
       "0  explanation edits made username hardcore metal...  \n",
       "1  d'aww matches background colour i'm seemingly ...  \n",
       "2  hey man i'm really trying edit war guy constan...  \n",
       "3  can't make real suggestions improvement wonder...  \n",
       "4               sir hero chance remember page that's  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e81173c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-28T03:58:22.914356Z",
     "start_time": "2023-03-28T03:58:21.880633Z"
    }
   },
   "outputs": [],
   "source": [
    "train[\"preprocess1\"] = train.apply(lambda x: x[\"comment_text\"] if len(x[\"preprocess\"])==0 else x['preprocess'], axis=1)\n",
    "test[\"preprocess1\"] = test.apply(lambda x: x[\"comment_text\"] if len(x[\"preprocess\"])==0 else x['preprocess'], axis=1)\n",
    "traindf=train[['preprocess1','toxic', 'severe_toxic', 'obscene', 'threat','insult', 'identity_hate']]\n",
    "testdf=test[['id','preprocess1']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe902a73",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-28T03:59:07.784867Z",
     "start_time": "2023-03-28T03:59:07.765225Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preprocess1</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>explanation edits made username hardcore metal...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d'aww matches background colour i'm seemingly ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hey man i'm really trying edit war guy constan...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>can't make real suggestions improvement wonder...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sir hero chance remember page that's</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         preprocess1  toxic  severe_toxic  \\\n",
       "0  explanation edits made username hardcore metal...      0             0   \n",
       "1  d'aww matches background colour i'm seemingly ...      0             0   \n",
       "2  hey man i'm really trying edit war guy constan...      0             0   \n",
       "3  can't make real suggestions improvement wonder...      0             0   \n",
       "4               sir hero chance remember page that's      0             0   \n",
       "\n",
       "   obscene  threat  insult  identity_hate  \n",
       "0        0       0       0              0  \n",
       "1        0       0       0              0  \n",
       "2        0       0       0              0  \n",
       "3        0       0       0              0  \n",
       "4        0       0       0              0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindf.head(5)\n",
    "# testdf.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c722e391",
   "metadata": {},
   "outputs": [],
   "source": [
    "traind=traindf[\"preprocess1\"]\n",
    "train_label=traindf[['toxic', 'severe_toxic', 'obscene', 'threat','insult', 'identity_hate']]\n",
    "testd=testdf[\"preprocess1\"]\n",
    "\n",
    "#prepare tokenizer\n",
    "tokenizer = Tokenizer(num_words = 30000) #only 30000 words considered here\n",
    "tokenizer.fit_on_texts(traind)\n",
    "\n",
    "#convert each text into array of integers with help of tokenizer.\n",
    "train_final = tokenizer.texts_to_sequences(traind)\n",
    "test_final = tokenizer.texts_to_sequences(testd)\n",
    "#Now lets pad the sentences. \n",
    "#From the above histogram it is evident that most of sentences falling in range 1-200 lengths. \n",
    "#max length=200 is kept \n",
    "#We will trim any sentence above that length and we will pad zeros for all the sentence below 200\n",
    "traind=pad_sequences(train_final, maxlen=200)\n",
    "testd=pad_sequences(test_final, maxlen=200)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
